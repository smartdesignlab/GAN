{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN in TensorFlow 2.0\n",
    "\n",
    "출처 : https://github.com/MonteChristo46/GAN-Notebooks/blob/master/GAN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 60000\n",
    "EPOCHES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the Data to tf.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.astype(\"float32\")\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "\n",
    "# data를 tensor에 넣음. (60000,28,28) -> (60000,784)로 reshape. 배치사이즈마다 데이터가 셔플됨.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images.reshape(train_images.shape[0],784)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "    \n",
    "    def __init__(self, random_noise_size = 100):\n",
    "        super().__init__(name='generator')\n",
    "        # layers 만듦\n",
    "        self.input_layer = keras.layers.Dense(units = random_noise_size)\n",
    "        self.dense_1 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_1 =  keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_2 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_2 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_3 = keras.layers.Dense(units = 256)\n",
    "        self.leaky_3 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.output_layer = keras.layers.Dense(units=784, activation = \"tanh\")\n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        # layer에 인풋 아웃풋 넣어서 순서대로 통과하게 만듦\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.leaky_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.leaky_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.leaky_3(x)\n",
    "        return  self.output_layer(x)\n",
    "    \n",
    "    # 랜덤 노이즈 생성\n",
    "    def generate_noise(self,batch_size, random_noise_size):\n",
    "        return np.random.uniform(-1,1, size = (batch_size, random_noise_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "\n",
    "def generator_objective(dx_of_gx):\n",
    "    # generator는 진짜 이미지라고 속여야 하기 떄문에 1매트릭스와 이미지를 비교해서 1에 가깝게 만듦\n",
    "    return cross_entropy(tf.ones_like(dx_of_gx), dx_of_gx) \n",
    "\n",
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__(name = \"discriminator\")\n",
    "        \n",
    "        # Layers 만듦\n",
    "        self.input_layer = keras.layers.Dense(units = 784)\n",
    "        self.dense_1 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_1 =  keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_2 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_2 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        self.dense_3 = keras.layers.Dense(units = 128)\n",
    "        self.leaky_3 = keras.layers.LeakyReLU(alpha = 0.01)\n",
    "        # output은 숫자 하나가 나와서 진짜인지 가짜인지 판별\n",
    "        self.logits = keras.layers.Dense(units = 1)  \n",
    "        \n",
    "    def call(self, input_tensor):\n",
    "        # layer에 인풋 아웃풋 넣어서 순서대로 통과하게 만듦\n",
    "        x = self.input_layer(input_tensor)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.leaky_1(x)\n",
    "        x = self.leaky_2(x)\n",
    "        x = self.leaky_3(x)\n",
    "        x = self.leaky_3(x)\n",
    "        x = self.logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_objective(d_x, g_z, smoothing_factor = 0.9):\n",
    "    \"\"\"\n",
    "    d_x = real output\n",
    "    g_z = fake output\n",
    "    \"\"\"\n",
    "    # 진짜 이미지는 1에 가깝게 학습, 가짜 이미지는 0에 가깝게 학습.\n",
    "    real_loss = cross_entropy(tf.ones_like(d_x) * smoothing_factor, d_x) \n",
    "    fake_loss = cross_entropy(tf.zeros_like(g_z), g_z) \n",
    "    \n",
    "    # 진짜이미지 loss와 가짜이미지 loss 합쳐서 loss로 정의\n",
    "    total_loss = real_loss + fake_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = keras.optimizers.RMSprop()\n",
    "discriminator_optimizer = keras.optimizers.RMSprop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def training_step(generator: Discriminator, discriminator: Discriminator, images:np.ndarray , k:int =1, batch_size = 32):\n",
    "    for _ in range(k):\n",
    "         with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            # 노이즈 생성, generator에 input으로 넣음\n",
    "            noise = generator.generate_noise(batch_size, 100)\n",
    "            g_z = generator(noise)\n",
    "            \n",
    "            # discriminator에 실제 이미지와, generator가 생성한 가짜 이미지 넣음\n",
    "            d_x_true = discriminator(images)\n",
    "            d_x_fake = discriminator(g_z)\n",
    "\n",
    "            discriminator_loss = discriminator_objective(d_x_true, d_x_fake)\n",
    "            \n",
    "            # gradient 조정하면서 학습\n",
    "            gradients_of_discriminator = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "            # gradient와 학습 파라미터를 가져와서 optimizer 돌림\n",
    "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables)) \n",
    "            \n",
    "              \n",
    "            # fake image를 discriminator가 1로 학습하도록 함 \n",
    "            generator_loss = generator_objective(d_x_fake)\n",
    "            # generator 학습\n",
    "            gradients_of_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)\n",
    "            # gradient와 학습 파라미터를 가져와서 optimizer 돌림\n",
    "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력을 위한 노이즈 생성\n",
    "seed = np.random.uniform(-1,1, size = (1, 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(dataset, epoches):\n",
    "    for epoch in range(epoches):\n",
    "        for batch in dataset: \n",
    "            training_step(generator, discriminator, batch ,batch_size = BATCH_SIZE, k = 1)\n",
    "            \n",
    "        ## After ith epoch plot image \n",
    "        if (epoch % 50) == 0: \n",
    "            fake_image = tf.reshape(generator(seed), shape = (28,28))\n",
    "            print(\"{}/{} epoches\".format(epoch, epoches))\n",
    "            plt.imshow(fake_image, cmap = \"gray\")\n",
    "#             plt.imsave(\"{}/{}.png\".format(OUTPUT_DIR,epoch),fake_image, cmap = \"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1000 epoches\n",
      "50/1000 epoches\n",
      "100/1000 epoches\n",
      "150/1000 epoches\n",
      "200/1000 epoches\n",
      "250/1000 epoches\n",
      "300/1000 epoches\n",
      "350/1000 epoches\n",
      "400/1000 epoches\n",
      "450/1000 epoches\n",
      "500/1000 epoches\n",
      "550/1000 epoches\n",
      "600/1000 epoches\n",
      "650/1000 epoches\n",
      "700/1000 epoches\n",
      "750/1000 epoches\n",
      "800/1000 epoches\n",
      "850/1000 epoches\n",
      "900/1000 epoches\n",
      "950/1000 epoches\n",
      "CPU times: user 21min 54s, sys: 3min 44s, total: 25min 38s\n",
      "Wall time: 24min 24s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "training(train_dataset, EPOCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAC+CAYAAACWL9wvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAFJElEQVR4nO3dy3LUMBQE0Jji/39ZLFKuUH6M7RBaV6NzdjBZMBen3dLIydJa+wAg41fvfwDATIQuQJDQBQgSugBBQhcg6PerF5dlmeJoQ2ttufu1ZnLMXPbMZM9MNF2AKKELECR0AYKELkCQ0AUIEroAQUIXIEjoDqy19vH3T4nb/hmoR+gCBL18Iq2nbWNblkcPSA1tfe9n73n7unb76WpuMzq7NmaeUe9s0XQBgso2Xe433tWs7WU7B42XyjRdgKByTdf+5P2GZk/3mIZrL/dIle8TTRcgSOgCBJXbXuC+KsulXmZ///ybXlstmi5AkKZbiCNg8POqrYg0XYAgTbeQ7RGwu4f8NeJP5uCo2Ag0XYAgTbeQ7+49eewV7uv9faLpAgSVabrVPmHsYbune/cx39537jSnPLijaqZougBBZZrumZlbTNU7NeOY+funKk0XIKh80+WcFsPKqmgcmi5AkKZbiLbCT7EK2qsyE00XIEjTLeBpw61yx06zEuAdaLoAQZruQGZtuGfMw9N5R6rPRNMFCBK6A2qtHe5vnv09UIfQBQgqu6dbbR/mf7jbSrezOJvNDDPjkxXNuDRdgKDuTffsju23IZz/fN3ZaHXcMcp1oukCBHVvumdmbXVHzILVKG2Oc5ouQJDQBQjqtr1gmQQ/xxbUXtWZaLoAQd2a7t1fL/7OHAl7xjVjBu9A0wUI6n5kTLszgyvms2cme6PMRNMFCOredOGpURoNHNF0AYKELkCQ0AUIEroAQUIXIGjxZAtAjqYLECR0AYKELkCQ0AUIEroAQUIXIEjoAgQJXYAgoQsQJHQBgoQuQJDQBQgSugBBQhcgSOgCBAldgCChCxAkdAGChC5AkNAFCBK6AEFCFyBI6AIECV2AIKELECR0AYKELkCQ0AUIEroAQUIXIEjoAgQJXYAgoQsQJHQBgoQuQJDQBQgSugBBQhcgSOgCBAldgCChCxAkdAGChC5AkNAFCBK6AEFCFyBI6AIECV2AIKELECR0AYKELkCQ0AUIEroAQUIXIEjoAgQJXYAgoQsQJHQBgoQuQJDQBQj6/erFZVla6h/SU2ttufu1ZnLMXPbMZM9MNF2AKKELECR0AYKELkCQ0AUIEroAQUIXIOjlOd2k1o6P7y3Lo+Oib2U7k5ln8fHhGnnFtTIOTRcgqEzT5bzJbV+frcWYy7X1va+zMJNzvVdMmi5AkKZbyLat8OlqLtqca2Ykmi5AkNCFN7Asi8Y/CKELECR0AYJ8kFaQD9SecTzq/Foxmy9VPojVdAGCyodua03jgws+SBtH+dAFeCfl93TdvVnZ6z5XZb+Sa5ouQFD5pgsrDfecVcC5aqsATRcgSNMtSFvhKdfMODRdgCBNtyD7c8eu5uLpK+7ofX1ougBBmu6AZm90Gi93VF0paroAQeWbrtbCU64VKtN0AYK6N92rfZcZW0vVvSgYQbUn0LY0XYCg7k2XPed0XzMXRqbpAgR1b7pa3fc52XHMXOZUfS93pekCBHVvunxftTt4itXRtVmvjRFougBBmi5va+a93Zne+2grHk0XIKh8053pjv2U2bxmLnOr+v+v6QIECV2AoPLbC1WXCAlXR6Nmns0rM87FMbpxaLoAQeWbrg+L4NqMDXfUFaCmCxBUpulWvzv1ZDbHzOXLdk93htmM+h41XYCgMk0X+Hejtr+ZaLoAQUIXIEjoAgQJXYAgoQsQtMz4JAtAL5ouQJDQBQgSugBBQhcgSOgCBAldgKA/yy+I7PaN3oMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_image = generator(np.random.uniform(-1,1, size = (10, 100)))\n",
    "\n",
    "r, c = 2, 5\n",
    "fig, axs = plt.subplots(r, c)\n",
    "cnt = 0\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axs[i,j].imshow(tf.reshape(fake_image[cnt], shape = (28,28)), cmap=\"gray\")\n",
    "        axs[i,j].axis('off')\n",
    "        cnt += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
