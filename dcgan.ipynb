{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCGAN\n",
    "\n",
    "출처 : https://neurowhai.tistory.com/148"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-9be9699d9187>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/lab1_lsh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/lab1_lsh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /home/lab1_lsh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/lab1_lsh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/lab1_lsh/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# mnist data 불러옴\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# epoch, batch size, noise 로 쓸 상수 변수 선언\n",
    "total_epoch = 100\n",
    "batch_size = 100\n",
    "n_noise = 100\n",
    " \n",
    "# 전역 변수로 쓸 변수 0으로 초기화\n",
    "D_global_step = tf.Variable(0, trainable=False, name='D_global_step')\n",
    "G_global_step = tf.Variable(0, trainable=False, name='G_global_step')\n",
    " \n",
    "# 이미지를 담는 변수 X와 노이즈 변수 Z\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "is_training = tf.placeholder(tf.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Leaky ReLU : ReLU가 음수영역에서 0을 출력하던 것과 달리, 약간의 기울기를 갖는 값을 출력한다.\n",
    "def leaky_relu(x, leak=0.2):\n",
    "    return tf.maximum(x, x * leak)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](leakyrelu.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 생성기(Generator) 모델 구성\n",
    "# DCGAN의 큰 특징 convlution layer와 batch normalization, 마지막은 tanh로 output이 나온다\n",
    "def generator(noise):\n",
    "    with tf.variable_scope('generator'):\n",
    "        output = tf.layers.dense(noise, 128*7*7)\n",
    "        output = tf.reshape(output, [-1, 7, 7, 128])\n",
    "        output = tf.nn.relu(tf.layers.batch_normalization(output, training=is_training))\n",
    "        output = tf.layers.conv2d_transpose(output, 64, [5, 5], strides=(2, 2), padding='SAME')\n",
    "        output = tf.nn.relu(tf.layers.batch_normalization(output, training=is_training))\n",
    "        output = tf.layers.conv2d_transpose(output, 32, [5, 5], strides=(2, 2), padding='SAME')\n",
    "        output = tf.nn.relu(tf.layers.batch_normalization(output, training=is_training))\n",
    "        output = tf.layers.conv2d_transpose(output, 1, [5, 5], strides=(1, 1), padding='SAME')\n",
    "        output = tf.tanh(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/dcgan1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 출처 : https://blog.naver.com/PostView.nhn?blogId=laonple&logNo=221201915691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 판별기(Discriminator) 모델 구성\n",
    "# leaky_relu, convolution layer를 사용. 마지막은 flatten 해준다. (그림에서는 sigmoid이지만 해당 코드에서는 그냥 flatten 해줌)\n",
    "def discriminator(inputs, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        \n",
    "        # scope.reuse_variables()이후에는 같은 scope내에서 같은 name을 갖는 변수를 새로 만들지 않고 재사용 한다.\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "            \n",
    "        output = tf.layers.conv2d(inputs, 32, [5, 5], strides=(2, 2), padding='SAME')\n",
    "        output = leaky_relu(output)\n",
    "        output = tf.layers.conv2d(output, 64, [5, 5], strides=(2, 2), padding='SAME')\n",
    "        output = leaky_relu(tf.layers.batch_normalization(output, training=is_training))\n",
    "        output = tf.layers.conv2d(output, 128, [5, 5], strides=(2, 2), padding='SAME')\n",
    "        output = leaky_relu(tf.layers.batch_normalization(output, training=is_training))\n",
    "        flat = tf.contrib.layers.flatten(output)\n",
    "        output = tf.layers.dense(flat, 1, activation=None)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/dcgan2.PNG)\n",
    "\n",
    "그림 dcgan2.PNG\n",
    "\n",
    "이미지 출처 : https://blog.naver.com/PostView.nhn?blogId=laonple&logNo=221201915691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 노이즈 생성\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1.0, 1.0, size=[batch_size, n_noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# interpolation 되는 과정을 보기위해 노이즈를 두개 생성하는 부분\n",
    "def get_moving_noise(batch_size, n_noise):\n",
    "    assert batch_size > 0\n",
    " \n",
    "    # 노이즈 두개 생성\n",
    "    noise_list = []\n",
    "    base_noise = np.random.uniform(-1.0, 1.0, size=[n_noise])\n",
    "    end_noise = np.random.uniform(-1.0, 1.0, size=[n_noise])\n",
    " \n",
    "    # 임의의 step 설정\n",
    "    step = (end_noise - base_noise) / batch_size\n",
    "    noise = np.copy(base_noise)\n",
    "    for _ in range(batch_size - 1):\n",
    "        noise_list.append(noise)\n",
    "        noise = noise + step\n",
    "    noise_list.append(end_noise)   # 변해가는 모습을 볼 수 있게 base 부터 end 까지 노이즈 리스트 만듦\n",
    "    \n",
    "    return noise_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z)\n",
    "D_real = discriminator(X)\n",
    "D_gene = discriminator(G, True)\n",
    "\n",
    "# loss 함수 cross entropy 사용\n",
    "loss_D_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "loss_G = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_gene, labels=tf.ones_like(D_gene)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차 엔트로피 (Cross Entropy)\n",
    "교차 엔트로피는 주로 범주형 데이터에 사용되는 손실함수이며, 다음과 같다.\n",
    "\n",
    "![](img/crossentropy.PNG)\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits_y_pred)\n",
    "loss = tf.reduce_mean(loss)\n",
    "\n",
    "교차 엔트로피는 두 분포 사이의 유사성을 측정하는 척도이다. 딥러닝에서의 분류 모델은 각 클래스의 확률값을 계산하므로 실제 클래스(y_true)와 모델이 예측한 클래스(y_pred)를 비교할 수 있으며, 두 분포가 가까울수록 교차 엔트로피값은 더 작아진다.\n",
    "\n",
    "출처: https://excelsior-cjh.tistory.com/151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tensorflow의 namefield를 이용해 변수를 재활용하기 위해 해당 collection의 variable들을 불러온다. \n",
    "# tf.get_collection(key)가 실행되면, key의 collection에 속하는 variable들의 리스트가 리턴된다.\n",
    "# 출처: https://eyeofneedle.tistory.com/24 [Technology worth spreading]\n",
    "\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='generator')\n",
    " \n",
    "# training 시점에서 변수 update_ops에 업데이트가 저장됨. 그래서 update_ops를 학습할 때 넣어준다.\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loss를 adamoptimizer를 이용해서 minimize하게 학습\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_D = tf.train.AdamOptimizer().minimize(loss_D,var_list=vars_D, global_step=D_global_step)\n",
    "    train_G = tf.train.AdamOptimizer().minimize(loss_G,var_list=vars_G, global_step=G_global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'loss_G:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# TensorBoard 사용하게 위해 loss값들을 기록\n",
    "tf.summary.scalar('loss_D', loss_D)\n",
    "tf.summary.scalar('loss_G', loss_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0000 D loss: 0.02907 G loss: 6.078\n",
      "Epoch: 0001 D loss: 0.1202 G loss: 4.496\n",
      "Epoch: 0002 D loss: 0.06606 G loss: 5.314\n",
      "Epoch: 0003 D loss: 0.1393 G loss: 8.347\n",
      "Epoch: 0004 D loss: 0.4249 G loss: 3.941\n",
      "Epoch: 0005 D loss: 0.4041 G loss: 4.288\n",
      "Epoch: 0006 D loss: 0.4792 G loss: 2.279\n",
      "Epoch: 0007 D loss: 0.3829 G loss: 3.653\n",
      "Epoch: 0008 D loss: 0.5859 G loss: 3.193\n",
      "Epoch: 0009 D loss: 0.734 G loss: 3.176\n",
      "Epoch: 0010 D loss: 1.302 G loss: 2.147\n",
      "Epoch: 0011 D loss: 0.4142 G loss: 3.214\n",
      "Epoch: 0012 D loss: 0.525 G loss: 2.279\n",
      "Epoch: 0013 D loss: 0.4454 G loss: 3.085\n",
      "Epoch: 0014 D loss: 0.4857 G loss: 2.556\n",
      "Epoch: 0015 D loss: 0.478 G loss: 2.82\n",
      "Epoch: 0016 D loss: 0.5847 G loss: 1.487\n",
      "Epoch: 0017 D loss: 0.6741 G loss: 3.33\n",
      "Epoch: 0018 D loss: 0.46 G loss: 1.847\n",
      "Epoch: 0019 D loss: 0.8492 G loss: 3.479\n",
      "Epoch: 0020 D loss: 0.8634 G loss: 1.13\n",
      "Epoch: 0021 D loss: 1.167 G loss: 1.825\n",
      "Epoch: 0022 D loss: 0.639 G loss: 2.068\n",
      "Epoch: 0023 D loss: 0.6697 G loss: 1.984\n",
      "Epoch: 0024 D loss: 0.6301 G loss: 1.972\n",
      "Epoch: 0025 D loss: 0.5148 G loss: 2.327\n",
      "Epoch: 0026 D loss: 0.6565 G loss: 2.3\n",
      "Epoch: 0027 D loss: 0.6536 G loss: 1.604\n",
      "Epoch: 0028 D loss: 0.7611 G loss: 1.795\n",
      "Epoch: 0029 D loss: 0.4582 G loss: 2.852\n",
      "Epoch: 0030 D loss: 0.4666 G loss: 3.431\n",
      "Epoch: 0031 D loss: 1.154 G loss: 2.66\n",
      "Epoch: 0032 D loss: 0.6258 G loss: 2.951\n",
      "Epoch: 0033 D loss: 0.4886 G loss: 1.489\n",
      "Epoch: 0034 D loss: 0.4574 G loss: 2.827\n",
      "Epoch: 0035 D loss: 0.7684 G loss: 2.315\n",
      "Epoch: 0036 D loss: 0.5545 G loss: 2.547\n",
      "Epoch: 0037 D loss: 1.026 G loss: 2.609\n",
      "Epoch: 0038 D loss: 0.3344 G loss: 4.168\n",
      "Epoch: 0039 D loss: 0.4717 G loss: 1.897\n",
      "Epoch: 0040 D loss: 0.4616 G loss: 2.854\n",
      "Epoch: 0041 D loss: 0.5543 G loss: 2.563\n",
      "Epoch: 0042 D loss: 0.5416 G loss: 3.799\n",
      "Epoch: 0043 D loss: 1.257 G loss: 1.067\n",
      "Epoch: 0044 D loss: 0.2191 G loss: 3.314\n",
      "Epoch: 0045 D loss: 0.3463 G loss: 3.754\n",
      "Epoch: 0046 D loss: 0.2322 G loss: 3.58\n",
      "Epoch: 0047 D loss: 0.2073 G loss: 2.277\n",
      "Epoch: 0048 D loss: 0.4137 G loss: 2.734\n",
      "Epoch: 0049 D loss: 0.3166 G loss: 5.358\n",
      "Epoch: 0050 D loss: 0.7031 G loss: 1.085\n",
      "Epoch: 0051 D loss: 0.1023 G loss: 4.362\n",
      "Epoch: 0052 D loss: 0.09769 G loss: 5.473\n",
      "Epoch: 0053 D loss: 0.312 G loss: 3.066\n",
      "Epoch: 0054 D loss: 0.4291 G loss: 3.258\n",
      "Epoch: 0055 D loss: 0.2741 G loss: 3.247\n",
      "Epoch: 0056 D loss: 0.4392 G loss: 2.743\n",
      "Epoch: 0057 D loss: 0.2945 G loss: 2.48\n",
      "Epoch: 0058 D loss: 0.4327 G loss: 4.422\n",
      "Epoch: 0059 D loss: 0.2953 G loss: 4.567\n",
      "Epoch: 0060 D loss: 0.1427 G loss: 5.014\n",
      "Epoch: 0061 D loss: 0.4876 G loss: 1.515\n",
      "Epoch: 0062 D loss: 0.2276 G loss: 3.55\n",
      "Epoch: 0063 D loss: 0.2033 G loss: 3.615\n",
      "Epoch: 0064 D loss: 0.2513 G loss: 3.213\n",
      "Epoch: 0065 D loss: 0.1801 G loss: 3.902\n",
      "Epoch: 0066 D loss: 0.08173 G loss: 4.24\n",
      "Epoch: 0067 D loss: 0.73 G loss: 4.982\n",
      "Epoch: 0068 D loss: 0.3479 G loss: 2.658\n",
      "Epoch: 0069 D loss: 0.139 G loss: 4.621\n",
      "Epoch: 0070 D loss: 0.186 G loss: 4.804\n",
      "Epoch: 0071 D loss: 0.09694 G loss: 3.157\n",
      "Epoch: 0072 D loss: 0.1273 G loss: 3.242\n",
      "Epoch: 0073 D loss: 0.8062 G loss: 1.48\n",
      "Epoch: 0074 D loss: 0.3094 G loss: 6.895\n",
      "Epoch: 0075 D loss: 0.09878 G loss: 5.624\n",
      "Epoch: 0076 D loss: 0.3249 G loss: 2.962\n",
      "Epoch: 0077 D loss: 0.1587 G loss: 3.929\n",
      "Epoch: 0078 D loss: 0.2165 G loss: 3.993\n",
      "Epoch: 0079 D loss: 0.1463 G loss: 3.276\n",
      "Epoch: 0080 D loss: 0.603 G loss: 2.965\n",
      "Epoch: 0081 D loss: 0.08803 G loss: 3.016\n",
      "Epoch: 0082 D loss: 0.09373 G loss: 3.686\n",
      "Epoch: 0083 D loss: 0.1198 G loss: 4.307\n",
      "Epoch: 0084 D loss: 0.2539 G loss: 4.461\n",
      "Epoch: 0085 D loss: 0.07144 G loss: 4.255\n",
      "Epoch: 0086 D loss: 0.1534 G loss: 3.823\n",
      "Epoch: 0087 D loss: 0.1359 G loss: 4.853\n",
      "Epoch: 0088 D loss: 0.1508 G loss: 2.507\n",
      "Epoch: 0089 D loss: 0.09045 G loss: 4.937\n",
      "Epoch: 0090 D loss: 0.2825 G loss: 3.82\n",
      "Epoch: 0091 D loss: 0.1382 G loss: 6.275\n",
      "Epoch: 0092 D loss: 0.09481 G loss: 5.916\n",
      "Epoch: 0093 D loss: 0.3046 G loss: 5.934\n",
      "Epoch: 0094 D loss: 0.287 G loss: 2.843\n",
      "Epoch: 0095 D loss: 0.2304 G loss: 3.66\n",
      "Epoch: 0096 D loss: 0.4144 G loss: 3.291\n",
      "Epoch: 0097 D loss: 0.0673 G loss: 5.339\n",
      "Epoch: 0098 D loss: 0.3471 G loss: 3.676\n",
      "Epoch: 0099 D loss: 0.1081 G loss: 4.82\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    " \n",
    "    merged = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter('./logs', sess.graph)  # 로그로 저장\n",
    " \n",
    "    total_batch = int(mnist.train.num_examples / batch_size)  # 전체 배치 사이즈 계산\n",
    " \n",
    "    for epoch in range(total_epoch):\n",
    "        loss_val_D, loss_val_G = 0, 0\n",
    " \n",
    "        batch_xs, batch_ys = None, None\n",
    "        noise = None\n",
    " \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "            noise = get_noise(batch_size, n_noise)\n",
    " \n",
    "            # 학습 돌림 \n",
    "            _, loss_val_D = sess.run([train_D, loss_D],feed_dict={X: batch_xs, Z: noise, is_training: True})\n",
    "            _, loss_val_G = sess.run([train_G, loss_G],feed_dict={X: batch_xs, Z: noise, is_training: True})\n",
    " \n",
    "        summary = sess.run(merged,feed_dict={X: batch_xs, Z: noise, is_training: True})\n",
    "        writer.add_summary(summary, global_step=sess.run(G_global_step)) # log로 저장\n",
    " \n",
    "        # epoch과 loss 프린트\n",
    "        print('Epoch:', '%04d' % epoch,\n",
    "            'D loss: {:.4}'.format(loss_val_D),\n",
    "            'G loss: {:.4}'.format(loss_val_G))\n",
    "     \n",
    "        # 5번째 마다 그림 보여줌 및 저장\n",
    "        if epoch == 0 or (epoch + 1) % 5 == 0:\n",
    "            sample_size = 10\n",
    "            noise = get_noise(sample_size, n_noise)\n",
    "            samples = sess.run(G, feed_dict={Z: noise, is_training: False})\n",
    "            test_noise = get_moving_noise(sample_size, n_noise)  # 두개의 노이즈 만들고 그 사이에 step을 더해서 noise list 가져옴\n",
    "            test_samples = sess.run(G, feed_dict={Z: test_noise, is_training: False})\n",
    " \n",
    "            fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    " \n",
    "            for i in range(sample_size):\n",
    "                ax[0][i].set_axis_off()\n",
    "                ax[1][i].set_axis_off()\n",
    "                ax[0][i].imshow(np.reshape(samples[i], (28, 28)))  # generator가 만든 그림들\n",
    "                ax[1][i].imshow(np.reshape(test_samples[i], (28, 28)))  # 두개의 노이즈를 만들어 interpolation되어가는 과정을 보여준 그림\n",
    "             \n",
    "            \n",
    "            plt.savefig('{}.png'.format(str(epoch).zfill(3)),bbox_inches='tight')\n",
    "            \n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫째줄 - Generator가 생성한 그림\n",
    "\n",
    "둘째줄 - 노이즈 두개를 생성해서 Z(latent vector)를 이용해 점점 변하는 것을 보여줌\n",
    "\n",
    "009.png\n",
    "![](img/009.png)\n",
    "\n",
    "054.png\n",
    "![](img/054.png)\n",
    "\n",
    "074.png\n",
    "![](img/074.png)\n",
    "\n",
    "099.png\n",
    "![](img/099.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
